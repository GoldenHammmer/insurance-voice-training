"use client";

import { useRef, useState } from "react";
import Link from "next/link";

type Gender = "male" | "female";
type Attitude = "neutral" | "skeptical" | "data_only" | "avoidant";
type Topic = "phone_invite" | "product_marketing" | "relationship";

export default function SessionPage() {
  const [gender, setGender] = useState<Gender>("male");
  const [age, setAge] = useState(38);
  const [job, setJob] = useState("å·¥å» æŠ€è¡“äººå“¡");
  const [attitude, setAttitude] = useState<Attitude>("neutral");
  const [topic, setTopic] = useState<Topic>("phone_invite");

  const [micReady, setMicReady] = useState(false);
  const [connected, setConnected] = useState(false);
  const [logLines, setLogLines] = useState<string[]>([]);

  const streamRef = useRef<MediaStream | null>(null);
  const pcRef = useRef<RTCPeerConnection | null>(null);
  const dcRef = useRef<RTCDataChannel | null>(null);
  const audioRef = useRef<HTMLAudioElement | null>(null);
  const personaReadyRef = useRef(false);

  function log(msg: string) {
    setLogLines((p) => [`[${new Date().toLocaleTimeString()}] ${msg}`, ...p].slice(0, 120));
  }

  async function enableMic() {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    streamRef.current = stream;
    setMicReady(true);
    log("Mic ready âœ…");
  }

  // é—œéµä¿®æ”¹é»1ï¼šbuildPersonaå‡½æ•¸ä¿æŒä¸è®Šï¼Œä½†æˆ‘å€‘æœƒåœ¨ä¸åŒåœ°æ–¹ä½¿ç”¨å®ƒ
  function buildPersona() {
    return `
ä½ æ˜¯ã€å°ç£çš„ä¿éšªå®¢æˆ¶ã€‘ï¼Œä¸æ˜¯æ¥­å‹™å“¡ã€‚

åŸºæœ¬è³‡æ–™ï¼š
- æ€§åˆ¥ï¼š${gender === "male" ? "ç”·æ€§" : "å¥³æ€§"}
- å¹´é½¡ï¼š${age} æ­²
- è·æ¥­ï¼š${job}
- åœ°å€ï¼šå°ç£
- èªè¨€ï¼šç¹é«”ä¸­æ–‡ï¼ˆå°ç£å£å»ï¼‰

æ…‹åº¦ï¼š
${attitude === "neutral" ? "ä¸­ç«‹ï¼Œé¡˜æ„è½ä½†ä¸ä¸»å‹•è²·" : ""}
${attitude === "skeptical" ? "è³ªç–‘æ¥­å‹™å‹•æ©Ÿ" : ""}
${attitude === "data_only" ? "åªæ¥å—æ•¸æ“š" : ""}
${attitude === "avoidant" ? "è½‰ç§»è©±é¡Œæƒ³çµæŸ" : ""}

æƒ…å¢ƒï¼š
${topic === "phone_invite" ? "é›»è©±ç´„è¨ª" : ""}
${topic === "product_marketing" ? "è¡ŒéŠ·ä¿éšªå•†å“" : ""}
${topic === "relationship" ? "å®¢æƒ…åŸ¹é¤Š" : ""}

è¦å‰‡ï¼š
- æ°¸é ä½¿ç”¨ç¹é«”ä¸­æ–‡
- æ¯æ¬¡åªå› 1ï½2 å¥
- æ¯å¥ä¸è¶…é 20 å­—
- ä¸ä¸»å‹•é–‹è©±é¡Œ
- ä¸å¯è·³å‡ºè§’è‰²
`;
  }

  async function startRealtime() {
    if (!streamRef.current) return;

    log("Starting realtimeâ€¦");

    const tokenRes = await fetch("/api/session/demo/ephemeral", { method: "POST" });
    const tokenJson = await tokenRes.json();
    const secret = tokenJson?.client_secret?.value;
    if (!secret) return;

    const pc = new RTCPeerConnection();
    pcRef.current = pc;

    const audio = document.createElement("audio");
    audio.autoplay = true;
    audio.muted = true;
    audio.setAttribute("playsinline", "true");
    audioRef.current = audio;

    pc.ontrack = (e) => {
      audio.srcObject = e.streams[0];
      log("AI track received (muted)");
    };

    streamRef.current.getTracks().forEach((t) => pc.addTrack(t, streamRef.current!));

    const dc = pc.createDataChannel("oai-events");
    dcRef.current = dc;

    dc.onopen = () => {
      log("DataChannel open âœ…");

      // é—œéµä¿®æ”¹é»2ï¼šåœ¨session.updateä¸­è¨­å®šå®Œæ•´çš„persona
      // é€™æ˜¯AIçš„åŸºç¤èº«ä»½è¨­å®š
      dc.send(
        JSON.stringify({
          type: "session.update",
          session: {
            modalities: ["audio", "text"],
            voice: "alloy",
            instructions: buildPersona(),
            max_output_tokens: 60,
            // å¯é¸ï¼šå¦‚æœä½ æƒ³è¦æ›´ç²¾ç¢ºçš„æ§åˆ¶ï¼Œå¯ä»¥åŠ ä¸Šé€™è¡Œ
            // turn_detection: null,
          },
        })
      );

      personaReadyRef.current = true;
      audio.muted = false;
      log("Persona injected & audio unmuted âœ…");
    };

    // é—œéµä¿®æ”¹é»3ï¼šåŠ å¼·äº‹ä»¶ç›£è½ï¼Œå¹«åŠ©ä½ è¨ºæ–·å•é¡Œ
    dc.onmessage = (e) => {
      const data = JSON.parse(e.data);
      
      // è¨˜éŒ„æ‰€æœ‰é‡è¦äº‹ä»¶
      if (data.type === "session.updated") {
        log("Session updated confirmed âœ…");
      }
      
      if (data.type === "response.done") {
        log("AI responded âœ…");
      }
      
      // å¦‚æœæœ‰éŒ¯èª¤ï¼Œç«‹åˆ»é¡¯ç¤º
      if (data.type === "error") {
        log("âŒ Error: " + JSON.stringify(data.error));
      }
    };

    const offer = await pc.createOffer();
    await pc.setLocalDescription(offer);

    const sdpRes = await fetch(
      "https://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview",
      {
        method: "POST",
        headers: {
          Authorization: `Bearer ${secret}`,
          "Content-Type": "application/sdp",
        },
        body: offer.sdp,
      }
    );

    const answer = await sdpRes.text();
    await pc.setRemoteDescription({ type: "answer", sdp: answer });

    setConnected(true);
    log("Realtime connected âœ…");
  }

  function startTalk() {
    log("ğŸ™ï¸ é–‹å§‹èªªè©±");
  }

  // é—œéµä¿®æ”¹é»4ï¼šé€™æ˜¯æ•´å€‹æ–¹æ¡ˆä¸‰çš„æ ¸å¿ƒä¿®æ”¹
  // æˆ‘å€‘æœ‰å…©å€‹ç‰ˆæœ¬è®“ä½ é¸æ“‡
  function stopTalk() {
    if (!dcRef.current || !personaReadyRef.current) return;

    log("ğŸ“¡ å‚³é€çµ¦ AI");

    // ç‰ˆæœ¬Aï¼šå®Œå…¨ç§»é™¤instructionsï¼Œè®“AIä¾è³´sessionå±¤ç´šçš„è¨­å®š
    // é€™æ˜¯æœ€ç°¡æ½”çš„åšæ³•ï¼Œä¹Ÿæ˜¯æˆ‘å»ºè­°ä½ å…ˆæ¸¬è©¦çš„ç‰ˆæœ¬
    dcRef.current.send(
      JSON.stringify({
        type: "response.create",
        response: {
          modalities: ["audio", "text"],
          // æ³¨æ„ï¼šé€™è£¡å®Œå…¨æ²’æœ‰instructionsæ¬„ä½
          // AIæœƒä½¿ç”¨ä½ åœ¨session.updateä¸­è¨­å®šçš„å®Œæ•´persona
        },
      })
    );

    // ç‰ˆæœ¬Bï¼šå¦‚æœç‰ˆæœ¬Aé‚„æ˜¯ä¸å¤ ï¼Œå°±ç”¨é€™å€‹ç‰ˆæœ¬
    // åœ¨æ¯æ¬¡å›æ‡‰æ™‚é‡è¤‡æé†’AIçš„å®Œæ•´èº«ä»½
    // ä½¿ç”¨é€™å€‹ç‰ˆæœ¬æ™‚ï¼Œè«‹æŠŠä¸Šé¢çš„ç‰ˆæœ¬Aè¨»è§£æ‰
    /*
    dcRef.current.send(
      JSON.stringify({
        type: "response.create",
        response: {
          modalities: ["audio", "text"],
          instructions: buildPersona() + "\n\nç¾åœ¨è«‹ä¾ç…§ä»¥ä¸Šè§’è‰²è¨­å®šç°¡çŸ­å›æ‡‰ã€‚",
        },
      })
    );
    */
  }

  function endRealtime() {
    dcRef.current?.close();
    pcRef.current?.close();
    setConnected(false);
    log("Session ended â›”");
  }

  return (
    <main style={{ maxWidth: 900, margin: "0 auto", padding: 32 }}>
      <Link href="/">â† å›é¦–é </Link>

      <h1>ä¿éšªèªéŸ³æ¨¡æ“¬</h1>

      <section>
        <select value={gender} onChange={(e) => setGender(e.target.value as Gender)}>
          <option value="male">ç”·æ€§</option>
          <option value="female">å¥³æ€§</option>
        </select>

        <input type="number" value={age} onChange={(e) => setAge(+e.target.value)} />
        <input value={job} onChange={(e) => setJob(e.target.value)} />

        <select value={attitude} onChange={(e) => setAttitude(e.target.value as Attitude)}>
          <option value="neutral">ä¸­ç«‹</option>
          <option value="skeptical">è³ªç–‘</option>
          <option value="data_only">åªçœ‹æ•¸æ“š</option>
          <option value="avoidant">è½‰ç§»è©±é¡Œ</option>
        </select>

        <select value={topic} onChange={(e) => setTopic(e.target.value as Topic)}>
          <option value="phone_invite">é›»è©±ç´„è¨ª</option>
          <option value="product_marketing">å•†å“è¡ŒéŠ·</option>
          <option value="relationship">å®¢æƒ…åŸ¹é¤Š</option>
        </select>
      </section>

      <section style={{ marginTop: 16 }}>
        {!micReady && <button onClick={enableMic}>å•Ÿç”¨éº¥å…‹é¢¨</button>}
        {micReady && !connected && <button onClick={startRealtime}>é–‹å§‹æ¨¡æ“¬</button>}
        {connected && (
          <>
            <button onMouseDown={startTalk} onMouseUp={stopTalk}>
              ğŸ™ï¸ æŒ‰ä½èªªè©±
            </button>
            <button onClick={endRealtime}>çµæŸ</button>
          </>
        )}
      </section>

      <pre style={{ marginTop: 24, background: "#111", color: "#0f0", padding: 12 }}>
        {logLines.join("\n")}
      </pre>
    </main>
  );
}
