"use client";

import { useEffect, useRef, useState } from "react";
import Link from "next/link";

export default function SessionPage() {
  // ===== åŸºæœ¬ç‹€æ…‹ =====
  const streamRef = useRef<MediaStream | null>(null);
  const pcRef = useRef<RTCPeerConnection | null>(null);
  const dcRef = useRef<RTCDataChannel | null>(null);
  const audioRef = useRef<HTMLAudioElement | null>(null);

  const [micReady, setMicReady] = useState(false);
  const [rtcConnected, setRtcConnected] = useState(false);
  const [logLines, setLogLines] = useState<string[]>([]);
  const sessionTimerRef = useRef<number | null>(null);

  function log(msg: string) {
    setLogLines((prev) => {
      const line = `[${new Date().toLocaleTimeString()}] ${msg}`;
      return [line, ...prev].slice(0, 80);
    });
  }

  // ===== å•Ÿç”¨éº¥å…‹é¢¨ =====
  async function enableMic() {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      streamRef.current = stream;
      setMicReady(true);
      log("Mic ready âœ…");
    } catch {
      alert("éº¥å…‹é¢¨å•Ÿç”¨å¤±æ•—ï¼Œè«‹ç¢ºèªç€è¦½å™¨æ¬Šé™");
    }
  }

  function stopAll() {
    sessionTimerRef.current && clearTimeout(sessionTimerRef.current);
    sessionTimerRef.current = null;

    dcRef.current?.close();
    pcRef.current?.close();
    streamRef.current?.getTracks().forEach((t) => t.stop());

    dcRef.current = null;
    pcRef.current = null;
    streamRef.current = null;

    setRtcConnected(false);
    setMicReady(false);
    log("Session ended â›”");
  }

  // ===== å•Ÿå‹• Realtime =====
  async function startRealtime() {
    if (!streamRef.current) {
      alert("è«‹å…ˆå•Ÿç”¨éº¥å…‹é¢¨");
      return;
    }

    log("Starting realtimeâ€¦");

    // 6 åˆ†é˜è‡ªå‹•çµæŸ
    sessionTimerRef.current = window.setTimeout(() => {
      log("â± 6 åˆ†é˜åˆ°ï¼Œç³»çµ±è‡ªå‹•çµæŸ");
      stopAll();
    }, 6 * 60 * 1000);

    const tokenRes = await fetch("/api/session/demo/ephemeral", { method: "POST" });
    const tokenJson = await tokenRes.json();
    const clientSecret = tokenJson?.client_secret?.value;

    const pc = new RTCPeerConnection();
    pcRef.current = pc;

    const dc = pc.createDataChannel("oai-events");
    dcRef.current = dc;

    dc.onopen = () => {
      log("DataChannel open âœ…");

      // ===== System Personaï¼ˆé‡é»ï¼‰=====
      dc.send(
        JSON.stringify({
          type: "session.update",
          session: {
            modalities: ["audio"],
            voice: "alloy",
            input_audio_format: "pcm16",
            output_audio_format: "pcm16",
            instructions: `
ä½ æ˜¯å°ç£çš„ä¿éšªå®¢æˆ¶ã€‚
åŸºæœ¬è¨­å®šï¼š
- æ€§åˆ¥ï¼šéš¨æ©Ÿ
- å¹´é½¡ï¼š35ï½50 æ­²
- è·æ¥­ï¼šä¸Šç­æ— / è‡ªç‡Ÿ
- å°ä¿éšªæ…‹åº¦ï¼šç†æ€§ä½†é˜²å‚™ï¼Œä¸å–œæ­¡è¢«æ¨éŠ·

äº’å‹•è¦å‰‡ï¼ˆéå¸¸é‡è¦ï¼‰ï¼š
- æ¯æ¬¡å›è¦†åªèƒ½ 1ï½2 å¥
- æ¯å¥ä¸è¶…é 20 å€‹ç¹é«”ä¸­æ–‡å­—
- å£èªã€è‡ªç„¶ã€åƒçœŸäºº
- ä¸è§£é‡‹ã€ä¸æ•™å­¸ã€ä¸èªªå¤§é“ç†

äººæ ¼å§¿æ…‹ï¼ˆéš¨æ©Ÿåˆ‡æ›ï¼‰ï¼š
- è²¬å‚™å‹ï¼šè³ªç–‘æ¥­å‹™å‹•æ©Ÿ
- è¨å¥½å‹ï¼šä¸æ•¢æ‹’çµ•ä½†ä¸ç­”æ‡‰
- è¶…ç†æ™ºå‹ï¼šåªè¦æ•¸æ“šèˆ‡é‚è¼¯
- æ‰“å²”å‹ï¼šè½‰ç§»è©±é¡Œã€æ•·è¡

ç¦æ­¢äº‹é …ï¼š
- ä¸å¾—é¼“å‹µè³¼è²·
- ä¸å¾—ä¿è­‰ä»»ä½•çµæœ
- ä¸å¾—è¬›èª²æˆ–é•·ç¯‡åˆ†æ
`,
          },
        })
      );
    };

    dc.onmessage = () => {}; // ä¸è™•ç† transcriptï¼Œçœ token

    // ===== Audio output =====
    const audio = document.createElement("audio");
    audio.autoplay = true;
    audio.setAttribute("playsinline", "true");
    audioRef.current = audio;

    pc.ontrack = (e) => {
      audio.srcObject = e.streams[0];
      audio.play();
      log("AI audio playing ğŸ”Š");
    };

    // ===== åŠ å…¥éº¥å…‹é¢¨ track =====
    streamRef.current.getTracks().forEach((track) => pc.addTrack(track, streamRef.current!));

    const offer = await pc.createOffer();
    await pc.setLocalDescription(offer);

    const sdpRes = await fetch(
      "https://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview",
      {
        method: "POST",
        headers: {
          Authorization: `Bearer ${clientSecret}`,
          "Content-Type": "application/sdp",
        },
        body: offer.sdp,
      }
    );

    const answer = await sdpRes.text();
    await pc.setRemoteDescription({ type: "answer", sdp: answer });

    setRtcConnected(true);
    log("Realtime connected âœ…");
  }

  // ===== Push-to-Talk =====
  function pushStart() {
    if (!dcRef.current) return;
    dcRef.current.send(JSON.stringify({ type: "input_audio_buffer.start" }));
    log("ğŸ™ é–‹å§‹èªªè©±");
  }

  function pushEnd() {
    if (!dcRef.current) return;
    dcRef.current.send(JSON.stringify({ type: "input_audio_buffer.commit" }));
    dcRef.current.send(JSON.stringify({ type: "response.create" }));
    log("ğŸ“¡ å‚³é€çµ¦ AI");
  }

  return (
    <main style={{ maxWidth: 720, margin: "0 auto", padding: 32 }}>
      <Link href="/">â† å›é¦–é </Link>

      <h1>èªéŸ³æ¨¡æ“¬å°è©±ï¼ˆMVPï¼‰</h1>

      {!micReady && (
        <button onClick={enableMic} style={{ padding: 12 }}>
          å•Ÿç”¨éº¥å…‹é¢¨
        </button>
      )}

      {micReady && !rtcConnected && (
        <button onClick={startRealtime} style={{ padding: 12 }}>
          é–‹å§‹ç·´ç¿’
        </button>
      )}

      {rtcConnected && (
        <>
          <button
            onMouseDown={pushStart}
            onMouseUp={pushEnd}
            onTouchStart={pushStart}
            onTouchEnd={pushEnd}
            style={{
              marginTop: 24,
              padding: "20px 40px",
              borderRadius: 999,
              background: "#7c3aed",
              color: "white",
              fontSize: 18,
            }}
          >
            æŒ‰ä½èªªè©±
          </button>

          <button onClick={stopAll} style={{ marginTop: 12 }}>
            çµæŸç·´ç¿’
          </button>
        </>
      )}

      <pre
        style={{
          marginTop: 24,
          background: "#0f172a",
          color: "#e5e7eb",
          padding: 12,
          borderRadius: 12,
          fontSize: 12,
          maxHeight: 240,
          overflow: "auto",
        }}
      >
        {logLines.join("\n")}
      </pre>
    </main>
  );
}
